{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMskKTQkz2vYr9OyqoA8pzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nsimaar99/Nsima-Project/blob/master/nsiudacity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M82h2oJZIdOh",
        "outputId": "bac75ae1-38eb-4ca1-b636-0fffa0396a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Nsima-Project'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 56 (delta 20), reused 20 (delta 20), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (56/56), 876.06 KiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nsimaar99/Nsima-Project.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "xua4OCHgMaHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\""
      ],
      "metadata": {
        "id": "PsP70ajlKgO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'flowers'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "metadata": {
        "id": "oL7pa6RBMs9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training, validation, and testing sets\n",
        "data_transforms =\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "image_datasets =\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "dataloaders ="
      ],
      "metadata": {
        "id": "dY2FHu_LNpoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label mapping\n",
        "You'll also need to load in a mapping from category label to category name. You can find this in the file cat_to_name.json. It's a JSON object which you can read in with the json module. This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
      ],
      "metadata": {
        "id": "cM0rhaCXOD_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "metadata": {
        "id": "tCDoSp9vOMAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building and training the classifier"
      ],
      "metadata": {
        "id": "fVUGNju2OgTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained network (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
        "# Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
        "# Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
        "# Track the loss and accuracy on the validation set to determine the best hyperparameters"
      ],
      "metadata": {
        "id": "eQ-lDU9kOVjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained network (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the pretrained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "id": "IU3vBWzeRogw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
        "from torch.nn import nn"
      ],
      "metadata": {
        "id": "7yNuYJbXSJlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.nn.Linear()"
      ],
      "metadata": {
        "id": "09z_ZwGbUvDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}